{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dmat(user_name,item_name,smat):\n",
    "    mat = np.zeros((len(user_name),len(item_name)))\n",
    "    for k,v in smat.items():\n",
    "        mat[user_name[k[0]],item_name[k[1]]] = v\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_user_feature(user_name,item_name,view_smat,order_smat):\n",
    "    user_feature = {}\n",
    "    #col0 = sex,col1= age_group,col2=view_count,col3=order_count\n",
    "    f=open(\"user-0331-0409.tsv\")\n",
    "    user_list = {}\n",
    "    for line_id,content in enumerate(f):\n",
    "        if(line_id==0):\n",
    "            continue\n",
    "        content = content[:-1] if (content[-1]==\"\\n\") else content\n",
    "        content = content.split(\"\\t\")\n",
    "        user_list[content[0]] = content[1:]\n",
    "    f.close()\n",
    "    \n",
    "    age_id = {\"20-34\":0, \"35-49\":1,\"50over\":2}\n",
    "    for user_id in user_name.keys():\n",
    "        user_feature[user_id] = []\n",
    "        user_feature[user_id].append(0 if user_list[user_id][0]==\"male\" else 1)\n",
    "        user_feature[user_id].append(age_id[user_list[user_id][1]])\n",
    "        user_feature[user_id] = user_feature[user_id]+user_list[user_id][2:]\n",
    "    view_dmat = make_dmat(user_name,item_name,view_smat)\n",
    "    order_dmat = make_dmat(user_name,item_name,order_smat)\n",
    "    view_count = np.sum(view_dmat,1)\n",
    "    order_count = np.sum(order_dmat,1)\n",
    "    for user_id,row_id in user_name.items():\n",
    "        user_feature[user_id] = user_feature[user_id]+[view_count[row_id],order_count[row_id]] \n",
    "    return user_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_item_feature(user_name,item_name,view_smat,order_smat):\n",
    "    item_feature = {}\n",
    "    #col0 = whole_view_count, col1 = male_view_count,col2=female_view_count\n",
    "    #col3= 20-34_view_count, col4= 35-50_view_count,col5 = 50over_view_count\n",
    "    #col6 = whole_order_count, col7 = male_order_count,col8=female_order_count\n",
    "    #col9= 20-34_order_count, col10= 35-50_order_count,col11 = 50over_order_count\n",
    "    \n",
    "    #import user list\n",
    "    f=open(\"user-0331-0409.tsv\")\n",
    "    user_list = {}\n",
    "    for line_id,content in enumerate(f):\n",
    "        if(line_id==0):\n",
    "            continue\n",
    "        content = content[:-1] if (content[-1]==\"\\n\") else content\n",
    "        content = content.split(\"\\t\")\n",
    "        user_list[content[0]] = content[1:]\n",
    "    f.close()\n",
    "    \n",
    "    #set feature dict\n",
    "    sex_view_id = {\"male\":1,\"female\":2}\n",
    "    sex_order_id = {\"male\":7,\"female\":8}\n",
    "    age_view_id = {\"20-34\":3, \"35-49\":4,\"50over\":5}\n",
    "    age_order_id = {\"20-34\":9, \"35-49\":10,\"50over\":11}\n",
    "    for k in item_name.keys():\n",
    "        item_feature[k] = [0 for i in range(12)]\n",
    "\n",
    "    for k,v in view_smat.items():\n",
    "        item_feature[k[1]][0] += v\n",
    "        item_feature[k[1]][sex_view_id[user_list[k[0]][0]]] += v\n",
    "        item_feature[k[1]][age_view_id[user_list[k[0]][1]]] += v\n",
    "    \n",
    "    for k,v in order_smat.items():\n",
    "        item_feature[k[1]][6] += v\n",
    "        item_feature[k[1]][sex_order_id[user_list[k[0]][0]]] += v\n",
    "        item_feature[k[1]][age_order_id[user_list[k[0]][1]]] += v\n",
    "    \n",
    "    return item_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def make_raw_feature(user_name,item_name,view_smat,order_smat,flag):\n",
    "    item_feature = make_item_feature(user_name,item_name,view_smat,order_smat)\n",
    "    user_feature = make_user_feature(user_name,item_name,view_smat,order_smat)\n",
    "    #col0~3:user_feature\n",
    "    #col4~15:item_feature\n",
    "    #col16= view_flag\n",
    "    #col17=order_flag\n",
    "    #col18 = user_sex_view_count\n",
    "    #col19 = user_age_view_count\n",
    "    #col20 = user_sex_order_count\n",
    "    #col21 = user_age_order_count\n",
    "    doc_prob = np.loadtxt(\"PATH-TO-LDA-OUTPUT1\",delimiter=\",\",skiprows=1)\n",
    "    word_prob = np.loadtxt(\"PATH-TO-LDA-OUTPUT2\",delimiter=\",\",skiprows=1)\n",
    "    res = doc_prob.dot(word_prob)\n",
    "\n",
    "    \n",
    "    sex_view_id = {0:1,1:2}\n",
    "    sex_order_id = {0:7,1:8}\n",
    "    age_view_id = {0:3, 1:4,2:5}\n",
    "    age_order_id = {0:9,1:10,2:11}\n",
    "    raw_varX = []\n",
    "    varY = []\n",
    "    if(flag==\"train\"):\n",
    "        f = open(\"train_target.tsv\",\"r\")\n",
    "    else:\n",
    "        f=open(\"target.tsv\",\"r\")\n",
    "    for line in f:\n",
    "        if(line[-1]== \"\\n\"):  line=line[:-1]\n",
    "        tmp = line.split(\"\\t\")\n",
    "        uid = tmp[0]\n",
    "        iid = tmp[1]\n",
    "        if(flag==\"train\"): varY.append(int(tmp[2]))\n",
    "        #add user_feature\n",
    "        if user_feature.has_key(uid):\n",
    "            varX_tmp = user_feature[uid] + list(doc_prob[user_name[uid],:])\n",
    "        else:\n",
    "            nTopic = len(doc_prob[0,:])\n",
    "            varX_tmp = [0 for i in range(len(user_feature[user_feature.keys()[0]]))]+[1.0/nTopic for i in range(nTopic)]\n",
    "        #add item_feature\n",
    "        if item_feature.has_key(iid):\n",
    "            varX_tmp =  varX_tmp+item_feature[iid] + list(word_prob[:,item_name[iid]])\n",
    "        else:\n",
    "            nTopic = len(doc_prob[0,:])\n",
    "            varX_tmp =  varX_tmp + [0 for i in range(nTopic+len(item_feature[item_feature.keys()[0]]))]\n",
    "        \n",
    "        #add user_and_item_feature\n",
    "        if user_feature.has_key(uid) and item_feature.has_key(iid):\n",
    "            if(view_smat.has_key((uid,iid))):\n",
    "                varX_tmp += [view_smat[(uid,iid)]]\n",
    "            else:\n",
    "                varX_tmp += [0]\n",
    "            if(order_smat.has_key((uid,iid))):\n",
    "                varX_tmp += [order_smat[(uid,iid)]]\n",
    "            else:\n",
    "                varX_tmp += [0]\n",
    "            varX_tmp += [item_feature[iid][sex_view_id[user_feature[uid][0]]]]\n",
    "            varX_tmp += [item_feature[iid][age_view_id[user_feature[uid][1]]]]\n",
    "            varX_tmp += [item_feature[iid][sex_order_id[user_feature[uid][0]]]]\n",
    "            varX_tmp += [item_feature[iid][age_order_id[user_feature[uid][1]]]]\n",
    "            varX_tmp += [res[user_name[uid],item_name[iid]]]\n",
    "        else:\n",
    "            varX_tmp =  varX_tmp + [0 for i in range(7)]\n",
    "        raw_varX.append(varX_tmp)\n",
    "    \n",
    "    category_col = [1]\n",
    "    cat = [[line[i] for i in category_col] for line in raw_varX]\n",
    "    enc = OneHotEncoder()\n",
    "    enc.fit(cat)\n",
    "    catnp = enc.transform(cat).toarray()\n",
    "    \n",
    "    numeric = [[line[i] for i in range(len(line)) if (not (i in category_col))] for line in raw_varX]\n",
    "    numeric = np.array(numeric)\n",
    "    varX = np.c_[catnp,numeric]\n",
    "    if(flag==\"train\"): varY=np.array(varY)\n",
    "    if(flag==\"train\"):\n",
    "        return varX,varY\n",
    "    else:\n",
    "        return varX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "def make_LDA_data(user_name,item_name,view_smat,order_smat):\n",
    "    view_dmat = make_dmat(user_name,item_name,view_smat)\n",
    "    order_dmat = make_dmat(user_name,item_name,order_smat)\n",
    "    train_mat = view_dmat + 10*order_dmat\n",
    "    transformer = TfidfTransformer()\n",
    "    tfidf = transformer.fit_transform(train_mat)\n",
    "    tfidf = tfidf.toarray()\n",
    "    np.savetxt(\"PATH-TO-LDA-INPUT\",tfidf,delimiter=\",\", fmt='%.2f'\n",
    "          ,header=\",\".join([\"X\"+str(i+1) for i in range(len(item_name))]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 2] No such file or directory: 'PATH-TO-WORK-DIR'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-794d18c6e3f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutl_func\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PATH-TO-WORK-DIR\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#construct simple counts for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtrain_view_smat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_item_view_smat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 2] No such file or directory: 'PATH-TO-WORK-DIR'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import col_names\n",
    "from utl_func import *\n",
    "\n",
    "os.chdir(\"PATH-TO-WORK-DIR\")\n",
    "#construct simple counts for \n",
    "train_view_smat = get_item_view_smat(\"train\")\n",
    "test_view_smat = get_item_view_smat(\"test\")\n",
    "train_order_smat = get_item_order_smat(\"train\")\n",
    "test_order_smat = get_item_order_smat(\"test\")\n",
    "whole_view_smat = get_item_view_smat(\"whole\")\n",
    "whole_order_smat = get_item_order_smat(\"whole\")\n",
    "\n",
    "#construct data for train\n",
    "user_name,item_name = get_user_and_item_name(whole_view_smat,whole_order_smat)\n",
    "make_LDA_data(user_name,item_name,train_view_smat,train_order_smat)\n",
    "#conduct C++ LDA for train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "varX,varY= make_raw_feature(user_name,item_name,train_view_smat,train_order_smat,\"train\")\n",
    "np.savetxt(\"data_for_train.tsv\",np.c_[varY,varX],delimiter=\"\\t\")\n",
    "#construct data for prediction \n",
    "make_LDA_data(user_name,item_name,whole_view_smat,whole_order_smat)\n",
    "#conduct C++ LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "varX= make_raw_feature(user_name,item_name,whole_view_smat,whole_order_smat,\"test\")\n",
    "np.savetxt(\"data_for_prediction.tsv\",varX,delimiter=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
